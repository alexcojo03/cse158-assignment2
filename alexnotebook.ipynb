{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1791ce9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>stream_id</th>\n",
       "      <th>streamer_username</th>\n",
       "      <th>time_start</th>\n",
       "      <th>time_stop</th>\n",
       "      <th>streamer_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11586</td>\n",
       "      <td>33827617344</td>\n",
       "      <td>miltontpike1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13762</td>\n",
       "      <td>33827755632</td>\n",
       "      <td>rekinss</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13762</td>\n",
       "      <td>33827475024</td>\n",
       "      <td>airon29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13762</td>\n",
       "      <td>33827351664</td>\n",
       "      <td>tonytubo</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13762</td>\n",
       "      <td>33827169440</td>\n",
       "      <td>eliasmerk</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>47618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3051728</th>\n",
       "      <td>8975</td>\n",
       "      <td>34415693328</td>\n",
       "      <td>purple_hs</td>\n",
       "      <td>6147</td>\n",
       "      <td>6148</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3051729</th>\n",
       "      <td>29709</td>\n",
       "      <td>34414041536</td>\n",
       "      <td>forsen</td>\n",
       "      <td>6147</td>\n",
       "      <td>6148</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3051730</th>\n",
       "      <td>41485</td>\n",
       "      <td>34416038384</td>\n",
       "      <td>rekkles</td>\n",
       "      <td>6147</td>\n",
       "      <td>6148</td>\n",
       "      <td>2524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3051731</th>\n",
       "      <td>84280</td>\n",
       "      <td>34413422016</td>\n",
       "      <td>dlxowns45</td>\n",
       "      <td>6147</td>\n",
       "      <td>6148</td>\n",
       "      <td>2190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3051732</th>\n",
       "      <td>74685</td>\n",
       "      <td>34415760240</td>\n",
       "      <td>lvpes2</td>\n",
       "      <td>6147</td>\n",
       "      <td>6148</td>\n",
       "      <td>1648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3051733 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id    stream_id streamer_username  time_start  time_stop  \\\n",
       "0          11586  33827617344      miltontpike1           0          5   \n",
       "1          13762  33827755632           rekinss           0          1   \n",
       "2          13762  33827475024           airon29           0          1   \n",
       "3          13762  33827351664          tonytubo           0          1   \n",
       "4          13762  33827169440         eliasmerk           0          1   \n",
       "...          ...          ...               ...         ...        ...   \n",
       "3051728     8975  34415693328         purple_hs        6147       6148   \n",
       "3051729    29709  34414041536            forsen        6147       6148   \n",
       "3051730    41485  34416038384           rekkles        6147       6148   \n",
       "3051731    84280  34413422016         dlxowns45        6147       6148   \n",
       "3051732    74685  34415760240            lvpes2        6147       6148   \n",
       "\n",
       "         streamer_id  \n",
       "0               1866  \n",
       "1               6845  \n",
       "2              18105  \n",
       "3               4949  \n",
       "4              47618  \n",
       "...              ...  \n",
       "3051728          727  \n",
       "3051729          202  \n",
       "3051730         2524  \n",
       "3051731         2190  \n",
       "3051732         1648  \n",
       "\n",
       "[3051733 rows x 6 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "data = pd.read_csv('100k_a.csv', names=['user_id', 'stream_id', 'streamer_username', 'time_start', 'time_stop'])\n",
    "# Create train and test splits temporally sorted by time_start\n",
    "data['streamer_id'], uniques = pd.factorize(data['streamer_username'])\n",
    "# start indexing at 0 instead of 1\n",
    "data['user_id'] = data['user_id'] - 1\n",
    "data = data.sort_values('time_start').reset_index(drop=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "33f54f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2441386, 610347)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_point = int(len(data) * 0.8)\n",
    "# split_point = 100000 # for reproducibility\n",
    "shuffled_data = data.sample(frac=1, random_state=42).reset_index()\n",
    "\n",
    "train_data = data.iloc[:split_point]\n",
    "test_data = data.iloc[split_point:]\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4ebcb082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98184"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemIDs = train_data['streamer_id'].unique().tolist()\n",
    "userIDs = train_data['user_id'].unique().tolist()\n",
    "len(userIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c4fc7915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2441386"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pairs of (user_id, streamer_id) in the training data\n",
    "trainInteractions = list(zip(train_data['user_id'], train_data['streamer_id']))\n",
    "# For each user id, this gets the set of consumed item ids (streamers they watched)\n",
    "user_consumed_items = train_data.groupby('user_id')['streamer_id'].apply(set).to_dict()\n",
    "len(trainInteractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "6fc9077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DO NOT DELETE THIS CODE BLOCK ###\n",
    "num_users = int(data['user_id'].max()) + 1\n",
    "num_items = int(data['streamer_id'].max()) + 1\n",
    "\n",
    "class MFModel(tf.keras.Model):\n",
    "    def __init__(self, K, lamb):\n",
    "        super(MFModel, self).__init__()\n",
    "        # Initialize variables\n",
    "        # self.betaI = tf.Variable(tf.random.normal([num_items],stddev=0.001))\n",
    "        self.gammaU = tf.Variable(tf.random.normal([num_users, K],stddev=0.01))\n",
    "        self.gammaI = tf.Variable(tf.random.normal([num_items, K],stddev=0.01))\n",
    "        # Regularization coefficient\n",
    "        self.lamb = lamb\n",
    "\n",
    "    # Prediction for a single instance\n",
    "    def predict(self, u, i):\n",
    "        p = tf.tensordot(self.gammaU[u], self.gammaI[i], 1)\n",
    "        return p\n",
    "    \n",
    "    def recommend(self, u, N=10):\n",
    "        u = tf.convert_to_tensor(u, dtype=tf.int64)\n",
    "        gamma_u = tf.nn.embedding_lookup(self.gammaU, u)\n",
    "        \n",
    "        # Compute dot product: (Items x K) . (K x 1) -> (Items x 1)\n",
    "        interaction_scores = tf.matmul(self.gammaI, tf.expand_dims(gamma_u, axis=-1))\n",
    "        \n",
    "        # Squeeze to (Items,) so it matches betaI shape\n",
    "        scores = tf.squeeze(interaction_scores, axis=-1)\n",
    "        \n",
    "        top_N = tf.math.top_k(scores, k=N)\n",
    "        return top_N.indices.numpy(), top_N.values.numpy()\n",
    "\n",
    "    # Regularizer\n",
    "    def reg(self):\n",
    "        return self.lamb * (tf.nn.l2_loss(self.gammaU) +\\\n",
    "                            tf.nn.l2_loss(self.gammaI))\n",
    "    \n",
    "    def score(self, sampleU, sampleI):\n",
    "        u = tf.convert_to_tensor(sampleU, dtype=tf.int64)\n",
    "        i = tf.convert_to_tensor(sampleI, dtype=tf.int64)\n",
    "        # beta_i = tf.nn.embedding_lookup(self.betaI, i)\n",
    "        gamma_u = tf.nn.embedding_lookup(self.gammaU, u)\n",
    "        gamma_i = tf.nn.embedding_lookup(self.gammaI, i)\n",
    "        x_ui = tf.reduce_sum(tf.multiply(gamma_u, gamma_i), 1)\n",
    "        return x_ui\n",
    "\n",
    "    def call(self, sampleU, sampleI, sampleJ):\n",
    "        x_ui = self.score(sampleU, sampleI)\n",
    "        x_uj = self.score(sampleU, sampleJ)\n",
    "        return -tf.reduce_mean(tf.math.log(tf.math.sigmoid(x_ui - x_uj)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c18ce29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Objective=0.6889206767082214\n",
      "Epoch 2: Objective=0.6974740624427795\n",
      "Epoch 3: Objective=0.6863889098167419\n",
      "Epoch 4: Objective=0.6926342844963074\n",
      "Epoch 5: Objective=0.6779004335403442\n",
      "Epoch 6: Objective=0.6827700138092041\n",
      "Epoch 7: Objective=0.690563976764679\n",
      "Epoch 8: Objective=0.6975968480110168\n",
      "Epoch 9: Objective=0.679886519908905\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[186]\u001b[39m\u001b[32m, line 68\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_BATCHES):\n\u001b[32m     67\u001b[39m     sampleU, sampleI = samplePositiveBatch(interactionsArr, BATCH_SIZE)\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     sampleJ = \u001b[43msampleNegativeBatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampleU\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampleI\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_consumed_arrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPrepeat\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m     loss = trainStepBatch(model, sampleU, sampleI, sampleJ)\n\u001b[32m     70\u001b[39m     \u001b[38;5;66;03m# if (i+1) % 1000 == 0:\u001b[39;00m\n\u001b[32m     71\u001b[39m     \u001b[38;5;66;03m#    print(f\"At batch {i+1}, Batch Objective={loss.numpy()}\")\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[186]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36msampleNegativeBatch\u001b[39m\u001b[34m(sampleU, sampleI, user_consumed_arrays, num_items, Prepeat)\u001b[39m\n\u001b[32m     36\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     37\u001b[39m     \u001b[38;5;66;03m# If user only watched 'i', fall through to random sampling below\u001b[39;00m\n\u001b[32m     38\u001b[39m \n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Logic: Sample from all items (Novel)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m j = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m j == i: \u001b[38;5;66;03m# Rejection sampling (fast)\u001b[39;00m\n\u001b[32m     42\u001b[39m     j = np.random.randint(\u001b[32m0\u001b[39m, num_items)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Train the model with batch\n",
    "LAMB = 0.00001\n",
    "LR = 0.01\n",
    "model = MFModel(20, LAMB)\n",
    "optimizer = tf.keras.optimizers.Adam(LR)\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "interactionsArr = np.array(trainInteractions)\n",
    "\n",
    "def samplePositiveBatch(interactionsArr, batch_size):\n",
    "    indices = np.random.choice(len(interactionsArr), batch_size)\n",
    "    batch_pos = interactionsArr[indices]\n",
    "    sampleU = batch_pos[:,0]\n",
    "    sampleI = batch_pos[:,1]\n",
    "\n",
    "    return sampleU, sampleI\n",
    "\n",
    "def sampleNegativeBatch(sampleU, sampleI, user_consumed_arrays, num_items, Prepeat=0.5):\n",
    "    batch_size = len(sampleU)\n",
    "    sampleJ = np.zeros(batch_size, dtype=np.int64)\n",
    "\n",
    "    for k in range(batch_size):\n",
    "        u = sampleU[k]\n",
    "        i = sampleI[k]\n",
    "        \n",
    "        # Logic: Try to sample from history (Repeat)\n",
    "        if np.random.rand() < Prepeat:\n",
    "            consumed = user_consumed_arrays[u]\n",
    "            \n",
    "            # We need a consumed item that is NOT 'i'.\n",
    "            # If the user has watched more than just 'i', we can proceed.\n",
    "            if len(consumed) > 1 or (len(consumed) == 1 and consumed[0] != i):\n",
    "                j = np.random.choice(consumed)\n",
    "                while j == i: # Rejection sampling (fast)\n",
    "                    j = np.random.choice(consumed)\n",
    "                sampleJ[k] = j\n",
    "                continue\n",
    "            # If user only watched 'i', fall through to random sampling below\n",
    "        \n",
    "        # Logic: Sample from all items (Novel)\n",
    "        j = np.random.randint(0, num_items)\n",
    "        while j == i: # Rejection sampling (fast)\n",
    "            j = np.random.randint(0, num_items)\n",
    "        sampleJ[k] = j\n",
    "\n",
    "    return sampleJ\n",
    "\n",
    "@tf.function\n",
    "def trainStepBatch(modela, sampleU, sampleI, sampleJ):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = modela.call(sampleU, sampleI, sampleJ)\n",
    "        loss += modela.reg()\n",
    "    \n",
    "    gradients = tape.gradient(loss, [modela.gammaU, modela.gammaI])\n",
    "    optimizer.apply_gradients(zip(gradients, [modela.gammaU, modela.gammaI]))\n",
    "    return loss\n",
    "\n",
    "BATCH_SIZE = 2**11 # 2^12=4096\n",
    "NUM_BATCHES = int(len(interactionsArr) / BATCH_SIZE)\n",
    "\n",
    "# Convert user_consumed_items to arrays for new negative sampling function\n",
    "user_consumed_arrays = {}\n",
    "for u in user_consumed_items:\n",
    "    user_consumed_arrays[u] = np.array(list(user_consumed_items[u]), dtype=np.int64)\n",
    "\n",
    "for epoch in range(100):\n",
    "    for i in range(NUM_BATCHES):\n",
    "        sampleU, sampleI = samplePositiveBatch(interactionsArr, BATCH_SIZE)\n",
    "        sampleJ = sampleNegativeBatch(sampleU, sampleI, user_consumed_arrays, num_items, Prepeat=0.5)\n",
    "        loss = trainStepBatch(model, sampleU, sampleI, sampleJ)\n",
    "        # if (i+1) % 1000 == 0:\n",
    "        #    print(f\"At batch {i+1}, Batch Objective={loss.numpy()}\")\n",
    "    print(f\"Epoch {epoch+1}: Objective={loss.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ece322cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SAVE THE MODEL ###\\\n",
    "# After training, save embeddings\n",
    "# np.save('betaI.npy', model.betaI.numpy())\n",
    "np.save('gammaU.npy', model.gammaU.numpy())\n",
    "np.save('gammaI.npy', model.gammaI.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d2750653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(162625, 20) dtype=float32, numpy=\n",
       "array([[-8.86068121e-02,  3.03519852e-02,  9.68260393e-02, ...,\n",
       "         2.43059799e-01,  2.88234019e+00,  1.21501759e-01],\n",
       "       [-1.15319360e-02, -1.42626604e-03,  2.89392658e-03, ...,\n",
       "        -1.32554248e-01,  1.79231837e-01,  1.26726385e-02],\n",
       "       [-3.75783741e-02,  4.94230678e-03, -2.90561408e-01, ...,\n",
       "        -6.49818033e-02,  1.67742372e+00, -1.23492397e-01],\n",
       "       ...,\n",
       "       [ 4.74854466e-03,  2.13176031e-02,  4.09641266e-02, ...,\n",
       "         2.03448720e-02, -6.37830496e-02, -1.59771722e-02],\n",
       "       [ 2.90319207e-04, -1.40437915e-03,  1.16859016e-03, ...,\n",
       "        -4.86185960e-02,  3.90350615e-04, -3.25675402e-03],\n",
       "       [ 8.52638696e-05,  3.06422031e-03, -2.82874302e-04, ...,\n",
       "        -5.61612724e-05,  1.45954476e-03, -1.14599585e-04]],\n",
       "      shape=(162625, 20), dtype=float32)>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In a new Python file or cell, recreate model with same sizes\n",
    "load_model = MFModel(K=20, lamb=LAMB)  # Same K and lamb, but lamb not needed for inference\n",
    "# Assign saved embeddings\n",
    "# load_model.betaI.assign(np.load('betaI.npy'))\n",
    "load_model.gammaU.assign(np.load('gammaU.npy'))\n",
    "load_model.gammaI.assign(np.load('gammaI.npy'))\n",
    "# Now use load_model.score() or load_model.predict() for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "42835e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation on 610347 pairs...\n",
      "Evaluated 256000...\n",
      "Evaluated 512000...\n",
      "Hit@1 prediction accuracy for novel interactions: 0.005870157791684263\n",
      "Hit@1 prediction accuracy for repeat interactions: 0.039599630727369904\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model with hit@1 (BATCHED)\n",
    "test_pairs = list(zip(test_data['user_id'], test_data['streamer_id']))\n",
    "\n",
    "\n",
    "# CRITICAL OPTIMIZATION: Convert list to set for O(1) lookup\n",
    "trainInteractionsSet = set(trainInteractions)\n",
    "\n",
    "hitkNovel = 0\n",
    "hitkNovelTotal = 0\n",
    "hitkRepeat = 0\n",
    "hitkRepeatTotal = 0\n",
    "\n",
    "# Create batches\n",
    "EVAL_BATCH_SIZE = 2**11\n",
    "num_test = len(test_pairs)\n",
    "K_TOP = 1  # Look at top 10 recommendations\n",
    "\n",
    "print(f\"Starting evaluation on {num_test} pairs...\")\n",
    "\n",
    "for i in range(0, num_test, EVAL_BATCH_SIZE):\n",
    "    batch = test_pairs[i : i + EVAL_BATCH_SIZE]\n",
    "    u_batch = [p[0] for p in batch]\n",
    "    i_batch = [p[1] for p in batch]\n",
    "    \n",
    "    # Get embeddings for this batch of users: (BatchSize, K)\n",
    "    u_tensor = tf.convert_to_tensor(u_batch, dtype=tf.int64)\n",
    "    batch_gamma_u = tf.nn.embedding_lookup(model.gammaU, u_tensor)\n",
    "    \n",
    "    # Compute scores for ALL items for these users: (BatchSize, K) x (K, NumItems) -> (BatchSize, NumItems)\n",
    "    # Note: Transpose gammaI to be (K, NumItems)\n",
    "    batch_scores = tf.matmul(batch_gamma_u, model.gammaI, transpose_b=True)\n",
    "    \n",
    "    # Get top K items\n",
    "    # Returns values and indices. We only need indices.\n",
    "    _, top_indices = tf.math.top_k(batch_scores, k=K_TOP)\n",
    "    top_indices = top_indices.numpy()\n",
    "    \n",
    "    # Check hits\n",
    "    for k in range(len(batch)):\n",
    "        uid, iid = batch[k]\n",
    "        pred_items = top_indices[k]\n",
    "        \n",
    "        if (uid, iid) in trainInteractionsSet:\n",
    "            if iid in pred_items:\n",
    "                hitkRepeat += 1\n",
    "            hitkRepeatTotal += 1\n",
    "        else:\n",
    "            if iid in pred_items:\n",
    "                hitkNovel += 1\n",
    "            hitkNovelTotal += 1\n",
    "            \n",
    "    if (i + EVAL_BATCH_SIZE) % 1000 == 0:\n",
    "        print(f\"Evaluated {i + EVAL_BATCH_SIZE}...\")\n",
    "\n",
    "print('Hit@1 prediction accuracy for novel interactions:', 1.0 * hitkNovel / hitkNovelTotal)\n",
    "print('Hit@1 prediction accuracy for repeat interactions:', 1.0 * hitkRepeat / hitkRepeatTotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "4048a269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3e-06"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.000003"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
