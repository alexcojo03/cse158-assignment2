{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "1791ce9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>stream_id</th>\n",
       "      <th>streamer_username</th>\n",
       "      <th>time_start</th>\n",
       "      <th>time_stop</th>\n",
       "      <th>streamer_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11586</td>\n",
       "      <td>33827617344</td>\n",
       "      <td>miltontpike1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13762</td>\n",
       "      <td>33827755632</td>\n",
       "      <td>rekinss</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13762</td>\n",
       "      <td>33827475024</td>\n",
       "      <td>airon29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13762</td>\n",
       "      <td>33827351664</td>\n",
       "      <td>tonytubo</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13762</td>\n",
       "      <td>33827169440</td>\n",
       "      <td>eliasmerk</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>47618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3051728</th>\n",
       "      <td>8975</td>\n",
       "      <td>34415693328</td>\n",
       "      <td>purple_hs</td>\n",
       "      <td>6147</td>\n",
       "      <td>6148</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3051729</th>\n",
       "      <td>29709</td>\n",
       "      <td>34414041536</td>\n",
       "      <td>forsen</td>\n",
       "      <td>6147</td>\n",
       "      <td>6148</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3051730</th>\n",
       "      <td>41485</td>\n",
       "      <td>34416038384</td>\n",
       "      <td>rekkles</td>\n",
       "      <td>6147</td>\n",
       "      <td>6148</td>\n",
       "      <td>2524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3051731</th>\n",
       "      <td>84280</td>\n",
       "      <td>34413422016</td>\n",
       "      <td>dlxowns45</td>\n",
       "      <td>6147</td>\n",
       "      <td>6148</td>\n",
       "      <td>2190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3051732</th>\n",
       "      <td>74685</td>\n",
       "      <td>34415760240</td>\n",
       "      <td>lvpes2</td>\n",
       "      <td>6147</td>\n",
       "      <td>6148</td>\n",
       "      <td>1648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3051733 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id    stream_id streamer_username  time_start  time_stop  \\\n",
       "0          11586  33827617344      miltontpike1           0          5   \n",
       "1          13762  33827755632           rekinss           0          1   \n",
       "2          13762  33827475024           airon29           0          1   \n",
       "3          13762  33827351664          tonytubo           0          1   \n",
       "4          13762  33827169440         eliasmerk           0          1   \n",
       "...          ...          ...               ...         ...        ...   \n",
       "3051728     8975  34415693328         purple_hs        6147       6148   \n",
       "3051729    29709  34414041536            forsen        6147       6148   \n",
       "3051730    41485  34416038384           rekkles        6147       6148   \n",
       "3051731    84280  34413422016         dlxowns45        6147       6148   \n",
       "3051732    74685  34415760240            lvpes2        6147       6148   \n",
       "\n",
       "         streamer_id  \n",
       "0               1866  \n",
       "1               6845  \n",
       "2              18105  \n",
       "3               4949  \n",
       "4              47618  \n",
       "...              ...  \n",
       "3051728          727  \n",
       "3051729          202  \n",
       "3051730         2524  \n",
       "3051731         2190  \n",
       "3051732         1648  \n",
       "\n",
       "[3051733 rows x 6 columns]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "data = pd.read_csv('100k_a.csv', names=['user_id', 'stream_id', 'streamer_username', 'time_start', 'time_stop'])\n",
    "# Create train and test splits temporally sorted by time_start\n",
    "data['streamer_id'], uniques = pd.factorize(data['streamer_username'])\n",
    "# start indexing at 0 instead of 1\n",
    "data['user_id'] = data['user_id'] - 1\n",
    "data = data.sort_values('time_start').reset_index(drop=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "33f54f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2441386, 610347)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_point = int(len(data) * 0.8)\n",
    "# split_point = 100000 # for reproducibility\n",
    "shuffled_data = data.sample(frac=1, random_state=42).reset_index()\n",
    "\n",
    "train_data = data.iloc[:split_point]\n",
    "test_data = data.iloc[split_point:]\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "4ebcb082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98184"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemIDs = train_data['streamer_id'].unique().tolist()\n",
    "userIDs = train_data['user_id'].unique().tolist()\n",
    "len(userIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "c4fc7915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2441386"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pairs of (user_id, streamer_id) in the training data\n",
    "trainInteractions = list(zip(train_data['user_id'], train_data['streamer_id']))\n",
    "# For each user id, this gets the set of consumed item ids (streamers they watched)\n",
    "user_consumed_items = train_data.groupby('user_id')['streamer_id'].apply(set).to_dict()\n",
    "len(trainInteractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "8ab58649",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = int(data['user_id'].max()) + 1\n",
    "num_items = int(data['streamer_id'].max()) + 1\n",
    "interactionsArr = np.array(trainInteractions)\n",
    "\n",
    "class MFModel(tf.keras.Model):\n",
    "    def __init__(self, K, lamb):\n",
    "        super(MFModel, self).__init__()\n",
    "        # Initialize with stddev=0.1 for better learning signal\n",
    "        self.gammaU = tf.Variable(tf.random.normal([num_users, K], stddev=0.1))\n",
    "        self.gammaI = tf.Variable(tf.random.normal([num_items, K], stddev=0.1))\n",
    "        self.lamb = lamb\n",
    "\n",
    "    def predict(self, u, i):\n",
    "        p = tf.tensordot(self.gammaU[u], self.gammaI[i], 1)\n",
    "        return p\n",
    "    \n",
    "    def recommend(self, u, N=10):\n",
    "        u = tf.convert_to_tensor(u, dtype=tf.int64)\n",
    "        gamma_u = tf.nn.embedding_lookup(self.gammaU, u)\n",
    "        interaction_scores = tf.matmul(self.gammaI, tf.expand_dims(gamma_u, axis=-1))\n",
    "        scores = tf.squeeze(interaction_scores, axis=-1)\n",
    "        top_N = tf.math.top_k(scores, k=N)\n",
    "        return top_N.indices.numpy(), top_N.values.numpy()\n",
    "\n",
    "    def reg(self):\n",
    "        return self.lamb * (tf.nn.l2_loss(self.gammaU) + tf.nn.l2_loss(self.gammaI))\n",
    "    \n",
    "    def score(self, sampleU, sampleI):\n",
    "        u = tf.convert_to_tensor(sampleU, dtype=tf.int64)\n",
    "        i = tf.convert_to_tensor(sampleI, dtype=tf.int64)\n",
    "        gamma_u = tf.nn.embedding_lookup(self.gammaU, u)\n",
    "        gamma_i = tf.nn.embedding_lookup(self.gammaI, i)\n",
    "        x_ui = tf.reduce_sum(tf.multiply(gamma_u, gamma_i), 1)\n",
    "        return x_ui\n",
    "\n",
    "    def call(self, inputs):\n",
    "        sampleU, sampleI, sampleJ = inputs\n",
    "        x_ui = self.score(sampleU, sampleI)\n",
    "        x_uj = self.score(sampleU, sampleJ)\n",
    "        return -tf.reduce_mean(tf.math.log(tf.math.sigmoid(x_ui - x_uj)))\n",
    "\n",
    "    # --- NEW: Custom Training Step for model.fit() ---\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data tuple (u, i, j) provided by the dataset\n",
    "        u, i, j = data\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self.call((u, i, j))\n",
    "            loss += self.reg()\n",
    "\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, [self.gammaU, self.gammaI])\n",
    "\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, [self.gammaU, self.gammaI]))\n",
    "\n",
    "        # Return metrics\n",
    "        return {\"loss\": loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "dfbd349c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computing negative samples for the entire dataset...\n",
      "Starting optimized training...\n",
      "Epoch 1/10\n",
      "\u001b[1m1272/9537\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m54s\u001b[0m 7ms/step - loss: 0.8120"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[232]\u001b[39m\u001b[32m, line 86\u001b[39m\n\u001b[32m     83\u001b[39m train_ds = create_fast_dataset(train_u, train_i, train_j, BATCH_SIZE)\n\u001b[32m     85\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarting optimized training...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/School/UCSD/FA2025/CSE158/cse158-assignment2/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/School/UCSD/FA2025/CSE158/cse158-assignment2/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:399\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    398\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    400\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001b[32m    401\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/School/UCSD/FA2025/CSE158/cse158-assignment2/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:241\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    238\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    239\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    240\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    242\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    243\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/School/UCSD/FA2025/CSE158/cse158-assignment2/.venv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/School/UCSD/FA2025/CSE158/cse158-assignment2/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/School/UCSD/FA2025/CSE158/cse158-assignment2/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/School/UCSD/FA2025/CSE158/cse158-assignment2/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/School/UCSD/FA2025/CSE158/cse158-assignment2/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/School/UCSD/FA2025/CSE158/cse158-assignment2/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/School/UCSD/FA2025/CSE158/cse158-assignment2/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/School/UCSD/FA2025/CSE158/cse158-assignment2/.venv/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/School/UCSD/FA2025/CSE158/cse158-assignment2/.venv/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "# 1. Enable Mixed Precision (Huge speedup on modern GPUs)\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "def samplePositiveBatch(interactionsArr, batch_size):\n",
    "    indices = np.random.choice(len(interactionsArr), batch_size)\n",
    "    batch_pos = interactionsArr[indices]\n",
    "    sampleU = batch_pos[:,0]\n",
    "    sampleI = batch_pos[:,1]\n",
    "\n",
    "    return sampleU, sampleI\n",
    "\n",
    "def sampleNegativeBatch(sampleU, sampleI, user_consumed_arrays, num_items, Prepeat=0.5):\n",
    "    batch_size = len(sampleU)\n",
    "    sampleJ = np.zeros(batch_size, dtype=np.int64)\n",
    "\n",
    "    for k in range(batch_size):\n",
    "        u = sampleU[k]\n",
    "        i = sampleI[k]\n",
    "        \n",
    "        # Logic: Try to sample from history (Repeat)\n",
    "        if np.random.rand() < Prepeat:\n",
    "            consumed = user_consumed_arrays[u]\n",
    "            \n",
    "            # We need a consumed item that is NOT 'i'.\n",
    "            # If the user has watched more than just 'i', we can proceed.\n",
    "            if len(consumed) > 1 or (len(consumed) == 1 and consumed[0] != i):\n",
    "                j = np.random.choice(consumed)\n",
    "                while j == i: # Rejection sampling (fast)\n",
    "                    j = np.random.choice(consumed)\n",
    "                sampleJ[k] = j\n",
    "                continue\n",
    "            # If user only watched 'i', fall through to random sampling below\n",
    "        \n",
    "        # Logic: Sample from all items (Novel)\n",
    "        j = np.random.randint(0, num_items)\n",
    "        while j == i: # Rejection sampling (fast)\n",
    "            j = np.random.randint(0, num_items)\n",
    "        sampleJ[k] = j\n",
    "\n",
    "    return sampleJ\n",
    "\n",
    "# 1. Wrapper to make your sampler compatible with tf.data\n",
    "def negative_sampling_wrapper(u, i):\n",
    "    # Convert to numpy for your existing function\n",
    "    u_np = u.numpy().astype(np.int64)\n",
    "    i_np = i.numpy().astype(np.int64)\n",
    "    # Call your existing logic\n",
    "    j_np = sampleNegativeBatch(u_np, i_np, user_consumed_arrays, num_items, Prepeat=0.5)\n",
    "    return j_np\n",
    "\n",
    "\n",
    "# Convert user_consumed_items to arrays for new negative sampling function\n",
    "user_consumed_arrays = {}\n",
    "for u in user_consumed_items:\n",
    "    user_consumed_arrays[u] = np.array(list(user_consumed_items[u]), dtype=np.int64)\n",
    "\n",
    "print(\"Pre-computing negative samples for the entire dataset...\")\n",
    "train_u = interactionsArr[:, 0]\n",
    "train_i = interactionsArr[:, 1]\n",
    "\n",
    "# Generate negatives ONCE. This might take 10-20 seconds but saves massive time later.\n",
    "train_j = sampleNegativeBatch(train_u, train_i, user_consumed_arrays, num_items, Prepeat=0.5)\n",
    "\n",
    "# Create a high-performance TensorFlow dataset\n",
    "# Since data is already prepared, we don't need tf.py_function anymore!\n",
    "def create_fast_dataset(u, i, j, batch_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((u, i, j))\n",
    "    dataset = dataset.shuffle(buffer_size=100000, reshuffle_each_iteration=True)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# 3. Initialize and Train\n",
    "LAMB = 0.000005\n",
    "LR = 0.1\n",
    "BATCH_SIZE = 2**8 # Larger batch size is better for GPU\n",
    "\n",
    "model = MFModel(K=20, lamb=LAMB)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(LR), jit_compile=True)\n",
    "\n",
    "train_ds = create_fast_dataset(train_u, train_i, train_j, BATCH_SIZE)\n",
    "\n",
    "print(\"Starting optimized training...\")\n",
    "history = model.fit(train_ds, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d92e977",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[215]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Plot the loss\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      4\u001b[39m plt.plot(history.history[\u001b[33m'\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      5\u001b[39m plt.title(\u001b[33m'\u001b[39m\u001b[33mTraining Loss\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# Plot the loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Training Loss')\n",
    "plt.ylabel('Loss')\n",
    "# filepath: /Users/alexcojocaru/School/UCSD/FA2025/CSE158/cse158-assignment2/alexnotebook.ipynb\n",
    "# Capture the history object\n",
    "history = model.fit(train_ds, epochs=10)\n",
    "\n",
    "# Plot the loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Training Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece322cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SAVE THE MODEL ###\\\n",
    "# After training, save embeddings\n",
    "# np.save('betaI.npy', model.betaI.numpy())\n",
    "np.save('gammaU.npy', model.gammaU.numpy())\n",
    "np.save('gammaI.npy', model.gammaI.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2750653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(162625, 20) dtype=float32, numpy=\n",
       "array([[-8.86068121e-02,  3.03519852e-02,  9.68260393e-02, ...,\n",
       "         2.43059799e-01,  2.88234019e+00,  1.21501759e-01],\n",
       "       [-1.15319360e-02, -1.42626604e-03,  2.89392658e-03, ...,\n",
       "        -1.32554248e-01,  1.79231837e-01,  1.26726385e-02],\n",
       "       [-3.75783741e-02,  4.94230678e-03, -2.90561408e-01, ...,\n",
       "        -6.49818033e-02,  1.67742372e+00, -1.23492397e-01],\n",
       "       ...,\n",
       "       [ 4.74854466e-03,  2.13176031e-02,  4.09641266e-02, ...,\n",
       "         2.03448720e-02, -6.37830496e-02, -1.59771722e-02],\n",
       "       [ 2.90319207e-04, -1.40437915e-03,  1.16859016e-03, ...,\n",
       "        -4.86185960e-02,  3.90350615e-04, -3.25675402e-03],\n",
       "       [ 8.52638696e-05,  3.06422031e-03, -2.82874302e-04, ...,\n",
       "        -5.61612724e-05,  1.45954476e-03, -1.14599585e-04]],\n",
       "      shape=(162625, 20), dtype=float32)>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In a new Python file or cell, recreate model with same sizes\n",
    "load_model = MFModel(K=20, lamb=LAMB)  # Same K and lamb, but lamb not needed for inference\n",
    "# Assign saved embeddings\n",
    "# load_model.betaI.assign(np.load('betaI.npy'))\n",
    "load_model.gammaU.assign(np.load('gammaU.npy'))\n",
    "load_model.gammaI.assign(np.load('gammaI.npy'))\n",
    "# Now use load_model.score() or load_model.predict() for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "42835e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation on 610347 pairs...\n",
      "Evaluated 256000...\n",
      "Evaluated 512000...\n",
      "Hit@1 prediction accuracy for novel interactions: 0.0\n",
      "Hit@1 prediction accuracy for repeat interactions: 1.71488837505752e-05\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model with hit@1 (BATCHED)\n",
    "test_pairs = list(zip(test_data['user_id'], test_data['streamer_id']))\n",
    "\n",
    "\n",
    "# CRITICAL OPTIMIZATION: Convert list to set for O(1) lookup\n",
    "trainInteractionsSet = set(trainInteractions)\n",
    "\n",
    "hitkNovel = 0\n",
    "hitkNovelTotal = 0\n",
    "hitkRepeat = 0\n",
    "hitkRepeatTotal = 0\n",
    "\n",
    "# Create batches\n",
    "EVAL_BATCH_SIZE = 2**11\n",
    "num_test = len(test_pairs)\n",
    "K_TOP = 1  # Look at top 10 recommendations\n",
    "\n",
    "print(f\"Starting evaluation on {num_test} pairs...\")\n",
    "\n",
    "for i in range(0, num_test, EVAL_BATCH_SIZE):\n",
    "    batch = test_pairs[i : i + EVAL_BATCH_SIZE]\n",
    "    u_batch = [p[0] for p in batch]\n",
    "    i_batch = [p[1] for p in batch]\n",
    "    \n",
    "    # Get embeddings for this batch of users: (BatchSize, K)\n",
    "    u_tensor = tf.convert_to_tensor(u_batch, dtype=tf.int64)\n",
    "    batch_gamma_u = tf.nn.embedding_lookup(model.gammaU, u_tensor)\n",
    "    \n",
    "    # Compute scores for ALL items for these users: (BatchSize, K) x (K, NumItems) -> (BatchSize, NumItems)\n",
    "    # Note: Transpose gammaI to be (K, NumItems)\n",
    "    batch_scores = tf.matmul(batch_gamma_u, model.gammaI, transpose_b=True)\n",
    "    \n",
    "    # Get top K items\n",
    "    # Returns values and indices. We only need indices.\n",
    "    _, top_indices = tf.math.top_k(batch_scores, k=K_TOP)\n",
    "    top_indices = top_indices.numpy()\n",
    "    \n",
    "    # Check hits\n",
    "    for k in range(len(batch)):\n",
    "        uid, iid = batch[k]\n",
    "        pred_items = top_indices[k]\n",
    "        \n",
    "        if (uid, iid) in trainInteractionsSet:\n",
    "            if iid in pred_items:\n",
    "                hitkRepeat += 1\n",
    "            hitkRepeatTotal += 1\n",
    "        else:\n",
    "            if iid in pred_items:\n",
    "                hitkNovel += 1\n",
    "            hitkNovelTotal += 1\n",
    "            \n",
    "    if (i + EVAL_BATCH_SIZE) % 1000 == 0:\n",
    "        print(f\"Evaluated {i + EVAL_BATCH_SIZE}...\")\n",
    "\n",
    "print('Hit@1 prediction accuracy for novel interactions:', 1.0 * hitkNovel / hitkNovelTotal)\n",
    "print('Hit@1 prediction accuracy for repeat interactions:', 1.0 * hitkRepeat / hitkRepeatTotal)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
